snippet = "%= erb tag"
<%= $1 %>
endsnippet

snippet % "% erb tag"
<% $1 %>
endsnippet

snippet each "each loop"
<%= @$1s.each do |${1:item}| %>
  ${2:todo}
<% end %>
endsnippet

snippet rendp "render a partial"
<%= render partial: '${1:filename}' %>
endsnippet

snippet fav "updating favicon"
<%= favicon_link_tag "/favicon.ico?v=2" %>
endsnippet

snippet lt "link_to"
<%= link_to "${1:link text}", ${2:link_path} %>
endsnippet

snippet ff "form for"
<%= form_for @${1:model} do |f| %>
  <p>
    <%= f.label :$2 %>
    <%= f.text_field :${2:attr} %>
  </p>

  <p>
    <%= f.submit %>
  </p>
<% end %>
endsnippet

snippet sff "simple form for"
<%= simple_form_for @${1:model} do |f| %>
  <%= f.input :${2:attribute} %>
  <%= f.button :submit %>
<% end %>
endsnippet

snippet flr "filler text: 1 paragraph"
<p>The technological singularity, or simply the singularity, is a hypothetical moment in time when artificial intelligence will have progressed to the point of a greater-than-human intelligence, radically changing civilization, and perhaps human nature. Since the capabilities of such an intelligence may be difficult for a human to comprehend, the technological singularity is often seen as an occurrence (akin to a gravitational singularity) beyond which the future course of human history is unpredictable or even unfathomable.</p>
endsnippet

snippet flr "filler text: 2 paragraphs"
<p>The technological singularity, or simply the singularity, is a hypothetical moment in time when artificial intelligence will have progressed to the point of a greater-than-human intelligence, radically changing civilization, and perhaps human nature. Since the capabilities of such an intelligence may be difficult for a human to comprehend, the technological singularity is often seen as an occurrence (akin to a gravitational singularity) beyond which the future course of human history is unpredictable or even unfathomable.</p>
<p>The first use of the term "singularity" in this context was by mathematician John von Neumann. In 1958, regarding a summary of a conversation with von Neumann, Stanislaw Ulam described "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue". The term was popularized by science fiction writer Vernor Vinge, who argues that artificial intelligence, human biological enhancement, or brain-computer interfaces could be possible causes of the singularity. Futurist Ray Kurzweil cited von Neumann's use of the term in a foreword to von Neumann's classic The Computer and the Brain.</p>
endsnippet

snippet flr "filler text: 3 paragraphs"
<p>The technological singularity, or simply the singularity, is a hypothetical moment in time when artificial intelligence will have progressed to the point of a greater-than-human intelligence, radically changing civilization, and perhaps human nature. Since the capabilities of such an intelligence may be difficult for a human to comprehend, the technological singularity is often seen as an occurrence (akin to a gravitational singularity) beyond which the future course of human history is unpredictable or even unfathomable.</p>
<p>The first use of the term "singularity" in this context was by mathematician John von Neumann. In 1958, regarding a summary of a conversation with von Neumann, Stanislaw Ulam described "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue". The term was popularized by science fiction writer Vernor Vinge, who argues that artificial intelligence, human biological enhancement, or brain-computer interfaces could be possible causes of the singularity. Futurist Ray Kurzweil cited von Neumann's use of the term in a foreword to von Neumann's classic The Computer and the Brain.</p>
<p>Proponents of the singularity typically postulate an "intelligence explosion", where superintelligences design successive generations of increasingly powerful minds, that might occur very quickly and might not stop until the agent's cognitive abilities greatly surpass that of any human.</p>
endsnippet

snippet flr "filler text: 4 paragraphs"
<p>The technological singularity, or simply the singularity, is a hypothetical moment in time when artificial intelligence will have progressed to the point of a greater-than-human intelligence, radically changing civilization, and perhaps human nature. Since the capabilities of such an intelligence may be difficult for a human to comprehend, the technological singularity is often seen as an occurrence (akin to a gravitational singularity) beyond which the future course of human history is unpredictable or even unfathomable.</p>
<p>The first use of the term "singularity" in this context was by mathematician John von Neumann. In 1958, regarding a summary of a conversation with von Neumann, Stanislaw Ulam described "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue". The term was popularized by science fiction writer Vernor Vinge, who argues that artificial intelligence, human biological enhancement, or brain-computer interfaces could be possible causes of the singularity. Futurist Ray Kurzweil cited von Neumann's use of the term in a foreword to von Neumann's classic The Computer and the Brain.</p>
<p>Proponents of the singularity typically postulate an "intelligence explosion", where superintelligences design successive generations of increasingly powerful minds, that might occur very quickly and might not stop until the agent's cognitive abilities greatly surpass that of any human.</p>
<p>Kurzweil predicts the singularity to occur around 2045 whereas Vinge predicts some time before 2030. At the 2012 Singularity Summit, Stuart Armstrong did a study of artificial generalized intelligence (AGI) predictions by experts and found a wide range of predicted dates, with a median value of 2040. His own prediction on reviewing the data is that there's an 80% probability that the singularity will occur between 2017 and 2112.</p>
endsnippet

snippet p "paragraph"
<p>${1:content}</p>
endsnippet

snippet d "div"
<div>
  ${1:content}
</div>
endsnippet

snippet c "class"
class="${1:class-name}"
endsnippet

snippet li "list"
<li>${1:content}</li>
endsnippet

snippet ol "ordered list"
<ol>
  ${1:content}
</ol>
endsnippet

snippet h "h1"
<h1>${1:content}</h1>
endsnippet

snippet h "h2"
<h2>${1:content}</h2>
endsnippet

snippet h "h3"
<h3>${1:content}</h3>
endsnippet

snippet h "h4"
<h4>${1:content}</h4>
endsnippet

snippet h "h5"
<h5>${1:content}</h5>
endsnippet
